{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6d08273",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "Code is free of any AI-generation, is completely organic, GMO-Free, Pesticide free and has no added preservatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "28a9f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d2b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given Dataset\n",
    "data = [\n",
    "    [12.0, 1.5, 1, 'Wine'],\n",
    "    [5.0, 2.0, 0, 'Beer'],\n",
    "    [40.0, 0.0, 1, 'Whiskey'],\n",
    "    [13.5, 1.2, 1, 'Wine'],\n",
    "    [4.5, 1.8, 0, 'Beer'],\n",
    "    [38.0, 0.1, 1, 'Whiskey'],\n",
    "    [11.5, 1.7, 1, 'Wine'],\n",
    "    [5.5, 2.3, 0, 'Beer']\n",
    "]\n",
    "\n",
    "test_data = np.array([\n",
    "    [6.0, 2.1, 0],   # Expected: Beer\n",
    "    [39.0, 0.05, 1], # Expected: Whiskey\n",
    "    [13.0, 1.3, 1]   # Expected: Wine\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "abc35e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes an integer and returns a label\n",
    "def encode_class_index(class_index):\n",
    "    match class_index:\n",
    "        case 'Beer': return 0\n",
    "        case 'Whiskey': return 1\n",
    "        case 'Wine': return 2\n",
    "        case _: raise Exception(\"Unknown Class\")\n",
    "\n",
    "# Takes an integer and returns a label\n",
    "def decode_class_index(class_index):\n",
    "    match class_index:\n",
    "        case 0: return 'Beer'\n",
    "        case 1: return 'Whiskey'\n",
    "        case 2: return 'Wine'\n",
    "        case _: raise Exception(\"Unknown Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978fcd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into features and labels\n",
    "X = np.array(tuple(data_point[:-1] for data_point in data))\n",
    "Y = np.array(tuple(encode_class_index(data_point[-1]) for data_point in data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7f2d7e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gini impurity, given an array of labels\n",
    "def gini(labels):\n",
    "    _, distribution = np.unique(labels, return_counts=True)\n",
    "    distribution = distribution/distribution.sum()\n",
    "\n",
    "    return 1 - (distribution**2).sum()\n",
    "\n",
    "# Calculate the gini impurity, given an array of labels\n",
    "def entropy(labels):\n",
    "    _, distribution = np.unique(labels, return_counts=True)\n",
    "    distribution = distribution/distribution.sum()\n",
    "\n",
    "    return -(distribution * np.log2(distribution)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7948b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Node class for the Decision Tree\n",
    "class Node:\n",
    "\n",
    "    # max_depth and metric need to be defined when instantiating root node\n",
    "    # It will be passed down to appropriate children\n",
    "    # metric can be either \"gini\" or \"entropy\"\n",
    "    def __init__(self, max_depth = 5, metric = 'gini'):\n",
    "        self.metric = metric\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "        # Decision Nodes will have a condition as well as a left and right child reference\n",
    "        self.feature_index = None \n",
    "        self.threshold = None\n",
    "        self.left = None  \n",
    "        self.right = None \n",
    "\n",
    "        # Leaf nodes will have a value stored\n",
    "        self.value = None \n",
    "\n",
    "    def _predict(self, X):\n",
    "        # If This is a leaf node, return stored value\n",
    "        if self.value is not None: return self.value\n",
    "\n",
    "        # Otherwise, apply the condition and go down to appropriate child \n",
    "        if (X[self.feature_index] < self.threshold): return self.left._predict(X)\n",
    "        else: return self.right._predict(X)  \n",
    "    \n",
    "    # Utility Wrapper function so you can pass in a single test point or multiple points\n",
    "    def predict(self, X):\n",
    "        if len(X.shape) > 0:\n",
    "            return np.array([\n",
    "                self._predict(point) for point in X\n",
    "            ])\n",
    "        else:\n",
    "            return self._predict(X)\n",
    "    \n",
    "    # Learning Algorithm using gini impurity\n",
    "    def _split_gini(self, X_train, Y_train):\n",
    "        impurity = gini(Y_train)\n",
    "\n",
    "        # Should this be a leaf node?\n",
    "        if impurity == 0 or self.max_depth == 1:\n",
    "            self.value = Y_train[0]\n",
    "            return\n",
    "        \n",
    "        # Find the best (feature,threshold) pair to split on\n",
    "        least_impurity = 2\n",
    "        best_feature = -1\n",
    "        best_threshold = -1\n",
    "\n",
    "\n",
    "        for feature in range(len(X_train[0])):\n",
    "            for threshold in X_train[:, feature]:\n",
    "                mask = X_train[:, feature] >= threshold\n",
    "                impurity_R = gini(Y_train[mask]) * mask.sum()\n",
    "                impurity_L = gini(Y_train[~ mask]) * (~ mask).sum()\n",
    "                impurity = (impurity_L + impurity_R)/len(mask)\n",
    "                if impurity < least_impurity:\n",
    "                    least_impurity = impurity\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        # Store condition\n",
    "        self.feature_index = best_feature\n",
    "        self.threshold = best_threshold\n",
    "\n",
    "        # Create child nodes\n",
    "        self.left = Node(max_depth=self.max_depth-1, metric=self.metric)\n",
    "        self.right = Node(max_depth=self.max_depth-1, metric=self.metric)\n",
    "\n",
    "        # Recursively make the child nodes learn\n",
    "        mask = X_train[:, self.feature_index] >= self.threshold\n",
    "        self.right.split(X_train[mask], Y_train[mask])\n",
    "        self.left.split(X_train[~ mask], Y_train[~ mask])\n",
    "\n",
    "    def _split_entropy(self, X_train, Y_train):\n",
    "        raise Exception(\"Not implemented\")\n",
    "\n",
    "    # Have the decision tree learn using the training data passed\n",
    "    # Utility wrapper function that calls the right implementation\n",
    "    def split(self, X_train, Y_train):\n",
    "        if self.metric == 'gini': self._split_gini(X_train, Y_train)\n",
    "        elif self.metric == 'entropy': self._split_gini(X_train, Y_train)\n",
    "        else: raise Exception(\"Unknown Metric \"+ str(self.metric))\n",
    "\n",
    "    # Pretty print the decision tree\n",
    "    # Works by recursively printing the tree in a DFS style \n",
    "    # while passing down indentation information\n",
    "    def pretty_print(self, feature_names, depth=0):        \n",
    "        if self.value is not None:\n",
    "            print(\"|   \"*(depth-1) + \"    \", end=\"\")\n",
    "            print(\"Prediction is:\", self.value)\n",
    "        \n",
    "        else:\n",
    "            print(\"|   \"*depth, end=\"\")\n",
    "            print(f\"IF {feature_names[self.feature_index]} >= {self.threshold}:\")\n",
    "            self.right.pretty_print(feature_names, depth+1)\n",
    "            print(\"|   \"*depth, end=\"\")\n",
    "            print(f\"ELSE:\")\n",
    "            self.left.pretty_print(feature_names, depth+1)\n",
    "\n",
    "        if (depth == 0): print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0be52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IF Alcohol >= 11.5:\n",
      "|   IF Alcohol >= 38.0:\n",
      "|       Prediction is: 1\n",
      "|   ELSE:\n",
      "|       Prediction is: 2\n",
      "ELSE:\n",
      "    Prediction is: 0\n",
      "\n",
      "('Beer', 'Whiskey', 'Wine')\n"
     ]
    }
   ],
   "source": [
    "# Create a Decision tree and fit it to the train dataset\n",
    "model = Node()\n",
    "model.split(X,Y)\n",
    "\n",
    "# Pretty print the decision tree\n",
    "model.pretty_print([\"Alcohol\", 'Sugar', \"Color\"])\n",
    "\n",
    "# Evaluate on the test set\n",
    "print(tuple(decode_class_index(x) for x in model.predict(test_data)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
